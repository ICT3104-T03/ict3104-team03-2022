{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Machine Learning with ToyotaHome/NVIDIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## READ ME:\n",
    "Run all cells in ascending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup/Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Functions to use along widgets\n",
    "from IPython.display import HTML, display, Markdown, Video, clear_output\n",
    "from ipywidgets import Layout\n",
    "# Faciliate file selection\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "# Widget Packages\n",
    "import ipywidgets as widgets\n",
    "# jupyter nbextension enable --py widgetsnbextension\n",
    "# Used for local directory\n",
    "import os\n",
    "import sys\n",
    "# import TSU.json_util as json_util\n",
    "# from TSU.json_util import test_train_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Install dependencies\n",
    "\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## install pytorch\n",
    "#pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Video Selector Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = os.getcwd() # print(os.path.basename(path)) # get the local directory\n",
    "videoSelector = widgets.Button(description = \"Select Video Preview\")\n",
    "videoClearer = widgets.Button(description = \"Clear Video Preview\")\n",
    "\n",
    "#Create the videoplayer here\n",
    "video_output = widgets.Output() # Customisation\n",
    "\n",
    "def video_Select(b):\n",
    "    root = Tk()\n",
    "    root.filename =  filedialog.askopenfilename(\n",
    "        initialdir = path,title = \"Select file\",filetypes = ((\"videos\",\"*.mp4\"),(\"all files\",\"*.*\")))\n",
    "    FileName = os.path.basename(root.filename)\n",
    "    # Get directory path\n",
    "    cwd = os.getcwd()\n",
    "    # Get file path\n",
    "    AbsoluteFilePath = os.path.normpath(root.filename)\n",
    "    # Replace file path's directory nonsense with the relative command\n",
    "    FilePath = AbsoluteFilePath.replace(cwd,\".\")\n",
    "    root.destroy() #Closes the Window\n",
    "    with video_output:\n",
    "        # Create Video File\n",
    "        video_output.clear_output()\n",
    "        html_video_code = '<video width=\"100%\" height=\"100%\" controls><source src=\"{filepath}\" type=\"video/mp4\"></video>'.format(filepath = FilePath)\n",
    "        video_output.append_display_data(HTML(html_video_code))\n",
    "\n",
    "def video_Clear(b):\n",
    "    with video_output:\n",
    "        video_output.clear_output()\n",
    "\n",
    "#Link the button to the function\n",
    "videoSelector.on_click(video_Select)\n",
    "videoClearer.on_click(video_Clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Shared Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "# selected_Directory = widgets.Text(\n",
    "#     description = 'Directory',\n",
    "#     value = '',\n",
    "#     placeholder = 'Select Directory'\n",
    "#     )\n",
    "# current_Directory = widgets.Label()\n",
    "# tooltip_Dir = widgets.Label(\"Current Directory: \")\n",
    "# selectDir = widgets.Button(description = \"Select Directory\")\n",
    "# clearDir = widgets.Button(description = \"Clear\")\n",
    "# confirmDir = widgets.Button(description = \"Confirm\")\n",
    "\n",
    "# sharedWidgets = widgets.VBox([widgets.HBox([tooltip_Dir,current_Directory]),widgets.HBox([selectDir, confirmDir, clearDir])])\n",
    "\n",
    "# def directory_Select(b):\n",
    "#     root = Tk()\n",
    "#     root.directory =  filedialog.askdirectory (\n",
    "#         initialdir = path)\n",
    "#     selected_Directory.value = root.directory\n",
    "#     root.destroy() #Closes the Window\\n\",\n",
    "\n",
    "# def directory_Clear(b):\n",
    "#     current_Directory.value = \"\"\n",
    "\n",
    "# def directory_Print(b):\n",
    "#     current_Directory.value = selected_Directory.value\n",
    "# selectDir.on_click(directory_Select)\n",
    "# clearDir.on_click(directory_Clear)\n",
    "# confirmDir.on_click(directory_Print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###  Toyota Widgets\n",
    "These are the widgets required to run Toyota ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Toyota = widgets.IntSlider(description = \"Toyo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### NVIDIA Widgets\n",
    "These are the widgets required to run NVIDIA ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Nvidia = widgets.IntSlider(description = \"Nvidia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Pre-requisites\n",
    "\"\"\"\n",
    "List of Machine Learning stuff\n",
    "Consider making it a text file to store/edit?\n",
    "\"\"\"\n",
    "ml_list = ['Toyota Smart Home', 'Nvidia STEP']\n",
    "\n",
    "# Widgets\n",
    "mlSelectConfirm = widgets.Button(description=\"Confirm\")\n",
    "menu = widgets.Dropdown(\n",
    "    options=ml_list,\n",
    "    value=ml_list[0],\n",
    "    description='ML Model:')\n",
    "\n",
    "# Output\n",
    "widgetset = widgets.Output()\n",
    "\n",
    "# Function\n",
    "def selectWidgetSet(b):\n",
    "    with widgetset:\n",
    "        widgetset.clear_output()\n",
    "        print(menu.value + \" is selected as the pipeline.\")\n",
    "#         if(menu.value == ml_list[0]): # if Toyota\n",
    "#             display(Toyota, sharedWidgets)\n",
    "#         elif(menu.value == ml_list[1]): # if Nvidia\n",
    "#             display(Nvidia, sharedWidgets)\n",
    "\n",
    "\n",
    "mlSelectConfirm.on_click(selectWidgetSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Caption videos function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import cv2\n",
    "import re\n",
    "import os\n",
    "\n",
    "class Captioning:\n",
    "    def __init__(self, annotation_file_path, truth_file_path, video_file):\n",
    "        self.sf = pandas.read_csv(annotation_file_path, header=0, names=['action','start','end','accuracy'], usecols=['action','start','end','accuracy'])[['action','start','end','accuracy']]\n",
    "        self.df = pandas.read_csv(truth_file_path)\n",
    "        self.video_path = video_file\n",
    "        self.time = 0\n",
    "        self.nextTime = 0\n",
    "        self.nextActionTime = 0\n",
    "        self.eventCounter = 0\n",
    "        self.actionCounter = 0\n",
    "        self.prediction = 0.0\n",
    "        self.ground_truth = \"\"\n",
    "        self.caption = \"\"\n",
    "        self.output_path = \"./videosCaptionOutput/\"\n",
    "\n",
    "    def getGroundTruth(self):\n",
    "        if self.time == 0:\n",
    "            self.nextTime = self.df['start_frame'].iloc[1]\n",
    "\n",
    "        if self.time >= self.nextTime:\n",
    "            try:\n",
    "                self.ground_truth = self.df['event'].iloc[self.eventCounter]\n",
    "                self.ground_truth =  re.sub('[_,.]', ' ', self.ground_truth)\n",
    "                self.nextTime = self.df['start_frame'].iloc[self.eventCounter+1]\n",
    "                self.eventCounter += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "    def getCaption(self):\n",
    "        if self.actionCounter == 0:\n",
    "            self.actionCounter, = self.sf.index[self.sf['end'] == 'end']\n",
    "            \n",
    "        if self.time >= self.nextActionTime:\n",
    "            self.actionCounter += 1\n",
    "            try: \n",
    "                self.nextActionTime = float(self.sf['end'].iloc[self.actionCounter])\n",
    "                self.caption = self.sf['action'].iloc[self.actionCounter]\n",
    "                self.caption =  re.sub('[_,.]', ' ', self.caption)\n",
    "                self.prediction = float(self.sf['accuracy'].iloc[self.actionCounter])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "    def saveVideo(self):\n",
    "        if not os.path.exists('./videosCaptionOutput/'):\n",
    "            os.makedirs('./videosCaptionOutput/')\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        # and our buffer to write frames\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(self.output_path+str(self.video_path[len(self.video_path)-13:len(self.video_path)-4])+'.mp4', fourcc, 25, (int(cap.get(3)),int(cap.get(4))))\n",
    "        if (cap.isOpened() == False):\n",
    "            print(\"Error opening video stream or file\")\n",
    "\n",
    "        while (cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(f'Video annotation is process complete.')\n",
    "                break\n",
    "\n",
    "            height, width, channels = frame.shape\n",
    "\n",
    "            self.time = int(cap.get(cv2.CAP_PROP_POS_MSEC)/40)\n",
    "            self.getGroundTruth()\n",
    "            self.getCaption()\n",
    "    \n",
    "#             print(self.time, self.caption)\n",
    "            cv2.rectangle(frame, (int(width * 0.05), int(height * 0.8)), (int(width * 0.95), int(height*0.95)), (159,159,159), -1)\n",
    "            cv2.putText(frame, \"Ground truth\", (int(width*0.1),int(height*0.85)), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,0), 2)\n",
    "            cv2.putText(frame, self.ground_truth, (int(width*0.3),int(height*0.85)), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,0), 2)\n",
    "            cv2.putText(frame, \"Prediction\", (int(width*0.1),int(height*0.9)), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,0), 2)\n",
    "            cv2.putText(frame, self.caption, (int(width*0.3),int(height*0.9)), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,0), 2)\n",
    "            cv2.putText(frame, \"Accuracy\", (int(width*0.65),int(height*0.9)), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,0), 2)\n",
    "            cv2.putText(frame, str(self.prediction), (int(width*0.8),int(height*0.9)), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,0), 2)\n",
    "\n",
    "            #write our frame\n",
    "            out.write(frame)\n",
    "            cv2.imshow('frame',frame)\n",
    "\n",
    "            key = cv2.waitKey(1)\n",
    "            # define the key to\n",
    "            # close the window\n",
    "            if key == 'q' or key == 27:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Usage Captioning(annotation_file_path, truth_file_path, video_file) \n",
    "# annotation_file_path (e.g. \"./data/generatedAnnotations/PDAN_TSU_RGB_P02T01C06.csv\" )\n",
    "# truth_file_path (e.g. \"./data/annotations/P02/P02T01C06.csv\" )\n",
    "# video_file (e.g. \"./data/rgbVideos/P02T01C06.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pipeline selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title = widgets.Label(\"Pipeline selection\")\n",
    "tooltip = widgets.Label(\"Supported Video Types: MP4, WebM, and OGG.\")\n",
    "\n",
    "mlBox = widgets.VBox([widgets.HBox([menu, mlSelectConfirm]),widgetset])\n",
    "toolBox = widgets.VBox([title,mlBox])\n",
    "\n",
    "toolBox\n",
    "\n",
    "### ML Widget Selector Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.1 Select a video to playback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "## retrieve all videos to dropdown list\n",
    "\n",
    "def populateList(fileDirectory, fileType):\n",
    "    folder_files = os.listdir(fileDirectory) #You can also use full path.\n",
    "    print(\"This Folder contains {len_folder} file(s).\".format(len_folder=len(folder_files)))\n",
    "    fileList = []\n",
    "    for file in folder_files:\n",
    "        if file.endswith(fileType):\n",
    "            fileList.append(file)\n",
    "    return fileList\n",
    "\n",
    "fileList = populateList('data/rgbVideos', \".mp4\")\n",
    "        \n",
    "## dropdown list to select video to play\n",
    "videoSelected = widgets.Dropdown(\n",
    "    options = fileList,\n",
    "    value= fileList[0],\n",
    "    description=\"Video: \",\n",
    "    disabled=False,\n",
    ")\n",
    "display(videoSelected)\n",
    "#https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20List.html#Button\n",
    "videoButton = widgets.Button(\n",
    "    description='Play video'\n",
    ")\n",
    "video_output = widgets.Output()\n",
    "def explore_video(b):\n",
    "    with video_output:\n",
    "        # Create Video File\n",
    "        video_output.clear_output()\n",
    "        html_video_code = '<video width=\"80%\" height=\"80%\" controls><source src=\"./data/rgbVideos/{fileName}\" type=\"video/mp4\"></video>'.format(fileName = videoSelected.value)\n",
    "        video_output.append_display_data(HTML(html_video_code))\n",
    "\n",
    "\n",
    "videoButton.on_click(explore_video)\n",
    "\n",
    "clearButton = widgets.Button(\n",
    "    description='Clear Playback'\n",
    ")\n",
    "\n",
    "def clear_video(b):\n",
    "    with video_output:\n",
    "        video_output.clear_output()\n",
    "        \n",
    "# display(clearButton)\n",
    "clearButton.on_click(clear_video)\n",
    "\n",
    "## to align the buttons to 1 row\n",
    "display(clearButton)\n",
    "display(videoButton, video_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Inference Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_dir = './TSU/models/'\n",
    "# listdir() returns a list containing the names of the entries in the directory given by path.\n",
    "modelList = os.listdir(\"./TSU/models\")\n",
    "\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "selectModel = widgets.Dropdown(\n",
    "    options = modelList,\n",
    "    value = modelList[0],\n",
    "    description = \"Choose a pre-trained model\",\n",
    "    style = style,\n",
    "    disabled= False\n",
    ")\n",
    "# Output for dataset upload\n",
    "selectModel\n",
    "# print(selectModel.value)\n",
    "select_button = widgets.Button(\n",
    "    description='Select Trained Model'\n",
    ")\n",
    "display(selectModel,select_button)\n",
    "\n",
    "# dropdown selected value --> selected_input_video.value\n",
    "def get_selected_value(b):\n",
    "    print(selectModel.value, \"is selected as the pre-trained model for inferencing.\")\n",
    "select_button.on_click(get_selected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Choose an input video from the TSU project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "## retrieve all TSU videos to dropdown list\n",
    "folder_files = os.listdir('data/rgbVideos') \n",
    "print(\"This Folder contains {len_folder} file(s).\".format(len_folder=len(folder_files)))\n",
    "fileList=[]\n",
    "for file in folder_files:\n",
    "    fileList.append(file)\n",
    "\n",
    "selected_input_video = widgets.Dropdown(\n",
    "    options = fileList,\n",
    "    value= fileList[0],\n",
    "    description=\"Video: \",\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "select_button = widgets.Button(\n",
    "    description='Select video'\n",
    ")\n",
    "\n",
    "\n",
    "display(selected_input_video, select_button)\n",
    "# dropdown selected value --> selected_input_video.value\n",
    "def get_selected_value(b):\n",
    "    print(selected_input_video.value, \"is selected as the video for inferencing.\")\n",
    "select_button.on_click(get_selected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Inference Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#see inference results in the form of output video with captions indicating detected activity in each video frame\n",
    "from util_modules.json_util.test_train_json import inference_json\n",
    "\n",
    "pretrain_model = selectModel.value\n",
    "video_name = selected_input_video.value\n",
    "dir = \"./TSU/models/\"+pretrain_model\n",
    "\n",
    "#using train_test to just load 1 video\n",
    "video_data = video_name.replace(\".mp4\",\"\")\n",
    "inference_output = inference_json(video_data, \"TSU\")\n",
    "print(\"Inference dataset generated: \", inference_output)\n",
    "'''\n",
    "to run this command, essential parameters to add are:\n",
    " -video_name\n",
    " -load_model\n",
    "Also do ensure you have a \"generatedAnnotations\" directory in the data folder \n",
    "in order to save the annotations.csv \n",
    "(\"./data/generatedAnnotations/\")\n",
    "'''\n",
    "\n",
    "%run ./TSU/inferencing.py -load_model $dir -video_name $video_name -dataset \"inference_smarthome_CS_51.json\" -dataset_type \"TSU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## display video with captions\n",
    "\n",
    "## get sub folder name e.g. \"P02\" from video name\n",
    "## dynamically retrieve annotations file based on user selected input\n",
    "sub_folder = video_name[:3]\n",
    "gt_annotation_directory = \"./data/annotations/{folder}/\".format(folder=sub_folder)\n",
    "generated_annotation_directory = \"./data/generatedAnnotations/\"\n",
    "annotation_file = video_name.replace(\".mp4\",\".csv\")\n",
    "gen_annotation_file = \"{loaded_model}_{vid_name}\".format(loaded_model=pretrain_model, vid_name=annotation_file)\n",
    "video_directory = \"./data/rgbVideos/{vid_name}\".format(vid_name=video_name)\n",
    "print(gt_annotation_directory)\n",
    "print(annotation_file)\n",
    "print(gen_annotation_file)\n",
    "\n",
    "test1 = Captioning(generated_annotation_directory+gen_annotation_file, gt_annotation_directory+annotation_file, video_directory)\n",
    "test1.saveVideo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Feature Extraction Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#! git clone https://github.com/v-iashin/video_features.git  ##need install manually, new version cant work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd video_features/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from video_features.utils.utils import build_cfg_path\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "from video_features.features_models.i3d.extract_i3d import ExtractI3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " ## Initialise the extraction class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Extraction:\n",
    "    \n",
    "    def __init__(self, feature_type):\n",
    "        self.args = OmegaConf.load(build_cfg_path(feature_type))\n",
    "        \n",
    "    def editExtraction(self, videos_txt, stream_type):\n",
    "        # self.args.show_pred = \"true\"\n",
    "        self.args.output_path = \"../dataExtractionOutput\"\n",
    "        self.args.video_paths = videos_txt\n",
    "        self.args.streams = stream_type\n",
    "        self.args.flow_type = \"raft\"\n",
    "        self.args.device = \"cuda:0\"\n",
    "        self.args.file_with_video_paths = \"\"\n",
    "        self.args.on_extraction = \"save_numpy\"\n",
    "        \n",
    "    def showArgs(self):\n",
    "        print(self.args)\n",
    "        \n",
    "    def runExtraction(self):\n",
    "        # Load the model\n",
    "        extractor = ExtractI3D(self.args)\n",
    "\n",
    "        # Extract features\n",
    "        for video_path in self.args.video_paths:\n",
    "            print(f'Extracting for {video_path}')\n",
    "            # save to output\n",
    "            extractor._extract(video_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Choose video to extract npy Feature File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Remember to increase jupyter notebook config locally to access videos more than 10MB\n",
    "\n",
    "In a new conda terminal type:\n",
    "`jupyter notebook --generate-config`\n",
    "\n",
    "Ctrl/Cmd F to replace tornado_settings to:\n",
    "`c.NotebookApp.tornado_settings = {\"websocket_max_message_size\": 10000 * 1024 * 1024}`\n",
    "\n",
    "Make sure to cd to the project root:\n",
    "`cd ~`\n",
    "\n",
    "Open your virtual environment:\n",
    "`new_env\\Scripts\\Activate`\n",
    "\n",
    "Run the jupyter notebook with the new configs:\n",
    "`jupyter notebook --config=\"jupyter_notebook_config.py\"`\n",
    "\n",
    "##### Link is here https://github.com/jupyter-widgets/ipywidgets/issues/2522"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "## retrieve all videos to dropdown list\n",
    "\n",
    "# Feature extraction title\n",
    "feature_videos_label = widgets.HTML(\n",
    "    value=\"<b>Upload your own videos to run feature extraction</b>\",\n",
    ")\n",
    "\n",
    "# Allow user to upload own videos\n",
    "feature_upload_videos = widgets.FileUpload(\n",
    "    accept='.mp4',  # Currently only accepts .mp4\n",
    "    multiple=True,\n",
    "    description = \"Browse\",\n",
    "    _counter = 0\n",
    ")\n",
    "\n",
    "# Choose the rgb/flow\n",
    "stream_option_hint = widgets.HTML(\n",
    "    value=\"(null = RGB+FLOW)\",\n",
    ")\n",
    "stream_option_selection = widgets.Select(\n",
    "    options=['null', 'rgb', 'flow'],\n",
    "    value='null',\n",
    "    description='Stream type:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Confirm button\n",
    "upload_feature_button = widgets.Button(\n",
    "    description='Confirm Extraction',\n",
    "    disabled = False\n",
    ")\n",
    "\n",
    "# retrieve function to run extraction tool\n",
    "extracted = Extraction('i3d')\n",
    "\n",
    "# Function to upload own dataset from computer\n",
    "def upload_videos(file_val):\n",
    "    if not file_val:\n",
    "        print (\"No file uploaded\")\n",
    "\n",
    "    else:   \n",
    "        uploaded_video_filename =[]\n",
    "        for item in file_val: \n",
    "            uploaded_video_filename.append(\"../data/rgbVideos/\"+item[\"name\"])\n",
    "            print(str(uploaded_video_filename))\n",
    "#             uploaded_video_filename = item[\"name\"]\n",
    "\n",
    "            # save the names\n",
    "            extracted.editExtraction(uploaded_video_filename, stream_option_selection.value)\n",
    "            extracted.runExtraction()\n",
    "            print(f'{uploaded_video_filename} is extracted to \"dataExtractionOutput\" folder successfully!')\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # resets\n",
    "            uploaded_file = ()\n",
    "            uploaded_filename = \"\"\n",
    "            content = \"\"\n",
    "        except:\n",
    "            print(sys.exc_info())\n",
    "            \n",
    "\n",
    "def on_feature_button_clicked(b):\n",
    "    upload_videos(feature_upload_videos.value)\n",
    "            \n",
    "\n",
    "upload_feature_button.on_click(on_feature_button_clicked)\n",
    "\n",
    "# User Interface\n",
    "uploadFeatureBox = widgets.VBox([feature_videos_label,\n",
    "                                 feature_upload_videos,\n",
    "                                 widgets.HBox([stream_option_selection, stream_option_hint]),\n",
    "                                 upload_feature_button\n",
    "                                 ])\n",
    "\n",
    "display(uploadFeatureBox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4. Training Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Selecting Dataset Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from util_modules.json_util.test_train_json import create_subset_json\n",
    "\n",
    "\n",
    "# Training Dataset Upload Label\n",
    "training_dataset_label = widgets.Label(\"Select dataset or upload your own\")\n",
    "\n",
    "# Create list for use with user dataset selection\n",
    "datasetList = populateList(\"./TSU/tsu_data\", \".json\") # populate list with files from dataset directory\n",
    "\n",
    "if not datasetList:\n",
    "    print (\"No existing datasets found\")\n",
    "\n",
    "# Allow user to select dataset\n",
    "selectedDataset = widgets.Dropdown(\n",
    "    options = datasetList,\n",
    "    value= datasetList[0],\n",
    "    description=\"Dataset: \",\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Allow user to upload own dataset\n",
    "training_upload_dataset = widgets.Button(\n",
    "    description='Upload dataset',\n",
    "    disabled = False\n",
    ")\n",
    "\n",
    "# Allow user to cancel upload\n",
    "training_upload_cancel = widgets.Button(\n",
    "    description='Cancel',\n",
    "    disabled = False\n",
    ")\n",
    "# Cancel upload functionality\n",
    "def upload_dataset_cancel(b):\n",
    "    with training_upload_output:\n",
    "        clear_output()\n",
    "        \n",
    "# Link cancel button        \n",
    "training_upload_cancel.on_click(upload_dataset_cancel)\n",
    "\n",
    "# Output for dataset upload\n",
    "training_upload_output = widgets.Output()\n",
    "\n",
    "# Function to upload own dataset from computer\n",
    "def upload_dataset(file_val):\n",
    "    if not file_val:\n",
    "        print (\"No file uploaded\")\n",
    "\n",
    "    else:   \n",
    "        clear_output(wait=True)\n",
    "        uploaded_file = next(iter(file_val))\n",
    "        uploaded_filename = uploaded_file[\"name\"]\n",
    "        content = uploaded_file[\"content\"]\n",
    "        print(\"File name: \" + uploaded_filename)\n",
    "\n",
    "        try:\n",
    "            save_path = './TSU/tsu_data/'\n",
    "            completeName = os.path.join(save_path, uploaded_filename) \n",
    "            with open(completeName, 'wb') as f: f.write(content)\n",
    "            print (uploaded_filename + \" uploaded to 'datasets' successfully!\")\n",
    "            \n",
    "            # resets\n",
    "            uploaded_file = ()\n",
    "            uploaded_filename = \"\"\n",
    "            content = \"\"\n",
    "        except:\n",
    "            print(sys.exc_info())\n",
    "            display(training_upload_cancel)\n",
    "\n",
    "# Upload functionality\n",
    "def show_upload(b):\n",
    "    with training_upload_output:\n",
    "        clear_output()\n",
    "        uploader = widgets.FileUpload(accept='.json',  # Currently only accepts .json\n",
    "                                      multiple=False,\n",
    "                                      description = \"Browse\",\n",
    "                                      _counter = 0\n",
    "        )\n",
    "        upload_button = widgets.Button(\n",
    "            description='Confirm Upload',\n",
    "            disabled = False\n",
    "        )\n",
    "\n",
    "        def on_button_clicked(b):\n",
    "            upload_dataset(uploader.value)\n",
    "\n",
    "        upload_button.on_click(on_button_clicked)\n",
    "        display(widgets.VBox([widgets.HBox([uploader, upload_button]),training_upload_cancel]))\n",
    "\n",
    "#Link the buttons\n",
    "training_upload_dataset.on_click(show_upload)\n",
    "\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "# User Interface\n",
    "uploadBox = widgets.VBox([training_dataset_label,\n",
    "                          widgets.HBox([selectedDataset,training_upload_dataset]),\n",
    "                         training_upload_output])\n",
    "\n",
    "# Provide user with batch size\n",
    "training_no = widgets.BoundedIntText(\n",
    "    min=1,\n",
    "    # max=1000, # to be defined and added as necessary\n",
    "    step=1,\n",
    "    description='No. of training:',\n",
    "    style=style,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Provide user with batch size\n",
    "testing_no = widgets.BoundedIntText(\n",
    "    min=1,\n",
    "    # max=1000, # to be defined and added as necessary\n",
    "    step=1,\n",
    "    description='No. of testing:',\n",
    "    style=style,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Confirm Button to provide user with virtual commit\n",
    "dataset_Confirm_Button = widgets.Button(\n",
    "    description='Confirm',\n",
    "    disabled = False\n",
    ")\n",
    "# Output to contain printout for ALL user input\n",
    "datasetOutput = widgets.Output()\n",
    "\n",
    "\n",
    "training_UserInput_label = widgets.Label(\"Current User Input\")\n",
    "# Functionality for user input\n",
    "def on_button_click(b):\n",
    "    with datasetOutput:\n",
    "        json_output = create_subset_json(testing_no.value, training_no.value, selectedDataset.value, \"./TSU/tsu_data/\", \"train_\" +selectedDataset.value, \"./TSU/tsu_data/\")\n",
    "        '''Print out the user input'''\n",
    "        datasetOutput.clear_output() # Clear previous output\n",
    "        print(\"Total train and test video data for training: \", json_output)\n",
    "\n",
    "dataset_Confirm_Button.on_click(on_button_click)\n",
    "\n",
    "dataset_input_box = widgets.HBox([widgets.VBox([uploadBox,training_no, testing_no,\n",
    "                         dataset_Confirm_Button,datasetOutput])])\n",
    "display(dataset_input_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set the Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Things I need; UI = UserInput\n",
    "'''\n",
    "-load_model = ./models/PDAN_TSU_RGB [ui]\n",
    "-mode = RGB [hardcoded]\n",
    "'''\n",
    "\n",
    "class user_input:\n",
    "    def __init__(self):\n",
    "        self.model_name = None\n",
    "        self.batch_size = None\n",
    "        self.epoch = None\n",
    "        self.kernelsize = None\n",
    "        self.mode = 'RGB'\n",
    "        self.comp_info = 'TSU_CS_RGB_PDAN'\n",
    "        self.train = True\n",
    "        self.dataset = 'TSU'\n",
    "        self.num_channel = 512\n",
    "        self.APtype = 'map'\n",
    "        self.model = 'PDAN'\n",
    "        self.lr = 0.0002\n",
    "\n",
    "        \n",
    "modes = ['rgb','skeleton']\n",
    "# Allow user to select type of TSU evaluation\n",
    "training_video_mode = widgets.Dropdown(\n",
    "    options = modes,\n",
    "    value= modes[0],\n",
    "    description=\"Video Type: \",\n",
    "    disabled=False,\n",
    ")\n",
    "        \n",
    "\n",
    "# Specify a name for this new model using appropriate UI elements.\n",
    "desired_model_name = widgets.Text(\n",
    "    placeholder='Type something..',\n",
    "    description='Model Name:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Create list for use with user dataset selection\n",
    "datasetList = populateList(\"./TSU/models\",\"\") # populate list with files from dataset directory\n",
    "\n",
    "if not datasetList:\n",
    "    print (\"No existing datasets found\")\n",
    "\n",
    "\n",
    "# Provide user with batch size\n",
    "user_batch_size = widgets.BoundedIntText(\n",
    "    min=1,\n",
    "    # max=1000, # to be defined and added as necessary\n",
    "    step=1,\n",
    "    description='Batch size:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Provide user with epoch selection\n",
    "epochs = widgets.BoundedIntText(\n",
    "    min=1,\n",
    "    # max=1000, # to be defined and added as necessary\n",
    "    step=1,\n",
    "    description='Epoch:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Provide user with kernel input\n",
    "kernel = widgets.BoundedIntText(\n",
    "    min=2,\n",
    "    # max=1000, # to be defined and added as necessary\n",
    "    step=1,\n",
    "    description='Kernel:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Confirm Button to provide user with virtual commit\n",
    "training_Confirm_Button = widgets.Button(\n",
    "    description='Confirm',\n",
    "    disabled = False\n",
    ")\n",
    "\n",
    "# Output to contain printout for ALL user input\n",
    "trainingParamOutput = widgets.Output()\n",
    "\n",
    "user = user_input() #Instantiate class here\n",
    "training_UserInput_label = widgets.Label(\"Current User Input\")\n",
    "# Functionality for user input\n",
    "def on_button_click(b):\n",
    "    with trainingParamOutput:\n",
    "        '''Store the user input into variables'''\n",
    "        userModelName = desired_model_name.value\n",
    "        userModelName = userModelName.replace(\" \", \"_\") # strip spaces\n",
    "        user.model_name = userModelName\n",
    "        user.batch_size = user_batch_size.value\n",
    "        user.epoch = epochs.value\n",
    "        user.kernelsize = kernel.value\n",
    "        user.mode = training_video_mode.value\n",
    "        '''Print out the user input'''\n",
    "        trainingParamOutput.clear_output() # Clear previous output\n",
    "        for item in vars(user): # Clear previous output\n",
    "            print(\"{}:{}\".format(item,vars(user)[item]))\n",
    "\n",
    "training_Confirm_Button.on_click(on_button_click)\n",
    "inputBox = widgets.HBox([widgets.VBox([training_video_mode,\n",
    "                         desired_model_name,\n",
    "                         user_batch_size, epochs, kernel,\n",
    "                         training_Confirm_Button]),widgets.VBox([training_UserInput_label,trainingParamOutput])])\n",
    "display(inputBox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run the training sequence, i.e., fit the model onto the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# os.chdir('../')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select Dataset\n",
    "split_setting = \"\"\n",
    "if \"CS\" in selectedDataset.value:\n",
    "    split_setting = \"CS\"\n",
    "elif \"CV\" in selectedDataset.value:\n",
    "    split_setting = \"CV\"\n",
    "\n",
    "bigRedButton = widgets.Button(\n",
    "    description='Train Model',\n",
    "    disabled = False,\n",
    "    button_style='danger'\n",
    ")\n",
    "\n",
    "train_data = \"train_\" + selectedDataset.value\n",
    "# print(\"Selected:\",selectedDataset.value)\n",
    "\n",
    "# Output train\n",
    "trainOutput = widgets.Output()\n",
    "\n",
    "# Functionality for user input\n",
    "def runTrain(b):\n",
    "    with trainOutput:\n",
    "        clear_output()\n",
    "        %run ./TSU/train.py -batch_size $user.batch_size \\\n",
    "        -model_name $user.model_name -epoch $user.epoch  \\\n",
    "        -kernelsize $user.kernelsize \\\n",
    "        -mode $user.mode -comp_info $user.comp_info -train $user.train \\\n",
    "        -dataset_type $user.dataset -num_channel $user.num_channel -APtype $user.APtype\\\n",
    "        -model $user.model -lr $user.lr -dataset $train_data\n",
    "\n",
    "bigRedButton.on_click(runTrain)\n",
    "display(widgets.VBox([bigRedButton,trainOutput]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5. Testing Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Choose a dataset subfolder, using appropriate UI elements, from the data folder to use for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Choose a dataset subfolder, using appropriate UI elements, from the data folder to use for testing\n",
    "\n",
    "# replicated from section 3\n",
    "existingBox = widgets.VBox([label_1, selectedDataset])\n",
    "newBox = widgets.VBox([label_2, selectown_button])\n",
    "selectBox = widgets.HBox([existingBox, newBox])\n",
    "display(selectBox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load a pretrained model using an appropriate UI component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load a pretrained model using an appropriate UI component\n",
    "\n",
    "# replicated from section 2\n",
    "selectModel\n",
    "# print(selectModel.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run the testing sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run the testing sequence, i.e., perform inference on each data sample and accumulate some statistics\n",
    "# (again check out the train.py file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## See some visual elements to indicate the progress of testing in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# •\tView some results \n",
    "# (e.g., Average Precision per activity class and mean Average Precision) \n",
    "# that allow for an assessment of how well the model performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Export results to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save the results to a results folder in the repo --> TBD\n",
    "\n",
    "from TSU import test as testpy\n",
    "\n",
    "def exportResultsOnClick(b):\n",
    "    testpy.output_csv(indexArray, frames, args.video_name, args.load_model, val_map, val_loss, classAccuracy)\n",
    "    print(\"working\")\n",
    "    \n",
    "exportResultsButton = widgets.Button(\n",
    "    description='Export results',\n",
    "    disabled = False\n",
    ")\n",
    "exportResultsButton.on_click(exportResultsOnClick)\n",
    "display(exportResultsButton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 7. New Pipeline (NVIDIA STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## STEP is just one other HOI project we suggest, but you are free to use any others. A good resource may be https://paperswithcode.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('new_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "62947cc9cd5e31609d34148b77c877bda5a1c80d1453f32153d4c79ba836d719"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
