{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affb04eb",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Run the cell below to import and install the dependencies needed for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0341066c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Functions to use along widgets\n",
    "##General Imports\n",
    "from IPython.display import HTML, display, Markdown, Video, clear_output\n",
    "from ipywidgets import Layout\n",
    "# Faciliate file selection\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "# Widget Packages\n",
    "import ipywidgets as widgets\n",
    "# jupyter nbextension enable --py widgetsnbextension\n",
    "# Used for local directory\n",
    "import os\n",
    "import sys\n",
    "# import TSU.json_util as json_util\n",
    "# from TSU.json_util import test_train_json\n",
    "\n",
    "from IPython.display import HTML\n",
    "from util_modules.ui_util.progress_bar import progress_bar\n",
    "\n",
    "##Imports for captioning\n",
    "import pandas\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "##Imports for Feature Extraction\n",
    "from os import walk\n",
    "from video_features.utils.utils import build_cfg_path\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "from video_features.features_models.i3d.extract_i3d import ExtractI3D\n",
    "\n",
    "##Imports for TSU\n",
    "from util_modules.json_util.test_train_json import inference_json\n",
    "\n",
    "##Imports for Second Algorithm (STEP/3D3)\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Show/hide code\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d4e8e9",
   "metadata": {},
   "source": [
    "# Welcome to the HOI Interactive Notebook Tool \n",
    "\n",
    "### Quick-Start:\n",
    "- Refer to the instructions and documentation provided in the Markdown cells of each of the sections below to better understand the functions of each feature.\n",
    "\n",
    "### Pre-Requisites:\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1a97ca",
   "metadata": {},
   "source": [
    "## 1. Initialisation\n",
    "Check if your device has a [CUDA-supported GPU](https://developer.nvidia.com/cuda-gpus#compute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "357f5f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d036c37e63364082a937e8d5f00f59c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Check if your device is CUDA supported', layout=Layout(height='40px',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada9e0f6b2974f78b71012abb8027866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# layout init.\n",
    "btn_layout = widgets.Layout(width='45%', height='40px')\n",
    "btn_sm_layout = widgets.Layout(width='20%', height='40px') \n",
    "label_layout = Layout(width='200px',height='auto')\n",
    "ddl_layout = widgets.Layout(width='45%', height= 'auto')\n",
    "\n",
    "\n",
    "# Widget\n",
    "btn_check_if_cuda = widgets.Button(description=\"Check if your device is CUDA supported\",\n",
    "    layout = btn_layout, button_style='info')\n",
    "\n",
    "cuda_output = widgets.Output()\n",
    "\n",
    "def check_if_cuda(b):\n",
    "    with cuda_output:\n",
    "        cuda_output.clear_output()\n",
    "        if (torch.cuda.is_available()):\n",
    "            print('Your computer is CUDA supported.')\n",
    "        else:\n",
    "            print('Your computer is not CUDA supported.')\n",
    "    # --- write script here to check if user's machine if cuda supported\n",
    "    return True\n",
    "\n",
    "btn_check_if_cuda.on_click(check_if_cuda)\n",
    "\n",
    "# Display\n",
    "display(btn_check_if_cuda, cuda_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f8a73d",
   "metadata": {},
   "source": [
    "## 2. Select Pipeline\n",
    "The following Machine Learning (ML) pipelines have been integrated with this project to allow you to have a hand at Activity Detection with ease. Click on any of the following links to learn more about their source repositiories if you're interested.\n",
    "- [Toyota Smarthome (TSU)](https://project.inria.fr/toyotasmarthome/)\n",
    "- [NVIDIA STEP)](https://github.com/NVlabs/STEP/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a61bb909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd69946b6e64dc993cec2a7a6fdfddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Select ML Pipeline:', layout=Layout(height='40px', width='45%'), options=…"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-requisites\n",
    "\"\"\"\n",
    "List of Machine Learning stuff\n",
    "Consider making it a text file to store/edit?\n",
    "\"\"\"\n",
    "ml_list = ['Toyota Smart Home', 'Nvidia STEP']\n",
    "\n",
    "# Widgets\n",
    "btn_select_pipeline = widgets.Button(description=\"Confirm\",\n",
    "    layout = btn_layout, button_style='info')\n",
    "\n",
    "ddl_pipeline = widgets.Dropdown(\n",
    "    options=ml_list,\n",
    "    value=ml_list[0],layout = btn_layout,\n",
    "    description='Select ML Pipeline:', style={'description_width': 'initial'})\n",
    "\n",
    "# Output\n",
    "widgetset = widgets.Output()\n",
    "\n",
    "# Function\n",
    "def selectWidgetSet(b):\n",
    "    with widgetset:\n",
    "        widgetset.clear_output()\n",
    "        print(ddl_pipeline.value + \" is selected as the pipeline.\")\n",
    "\n",
    "btn_select_pipeline.on_click(selectWidgetSet)\n",
    "\n",
    "# Display\n",
    "tooltip = widgets.Label(\"Supported Video Types: MP4, WebM, and OGG.\")\n",
    "mlBox = widgets.VBox([ddl_pipeline,btn_select_pipeline,widgetset])\n",
    "mlBox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3d5ea",
   "metadata": {},
   "source": [
    "## 3. Data Exploration\n",
    "Select and view playback of any video from the `data` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b80c80ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`data/rgbVideos` directory contains 536 file(s).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d8c18daa994b4ba6161f6211d16c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Select Video(s):', layout=Layout(height='auto', width='200px')), Dr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9efbd8f847545e795b8432465284020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Clear Playback', layout=Layout(height='40px', width='20%'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logic\n",
    "def populateList(fileDirectory, fileType):\n",
    "    folder_files = os.listdir(fileDirectory) #You can also use full path.\n",
    "    print(\"`data/rgbVideos` directory contains {len_folder} file(s).\".format(len_folder=len(folder_files)))\n",
    "    fileList = []\n",
    "    for file in folder_files:\n",
    "        if file.endswith(fileType):\n",
    "            fileList.append(file)\n",
    "    return fileList\n",
    "\n",
    "fileList = populateList('data/rgbVideos', \".mp4\")\n",
    "        \n",
    "# Widget\n",
    "label_data_files= widgets.Label(\"Select Video(s):\", layout = label_layout)\n",
    "ddl_data_selected = widgets.Dropdown(\n",
    "    options = fileList,\n",
    "    value= fileList[0],\n",
    "    layout = ddl_layout)\n",
    "\n",
    "btn_video = widgets.Button(\n",
    "    description='Play video', layout = btn_sm_layout, button_style='info'\n",
    ")\n",
    "\n",
    "btn_clear = widgets.Button(\n",
    "    description='Clear Playback', layout = btn_sm_layout\n",
    ")\n",
    "\n",
    "# Display output\n",
    "video_output = widgets.Output()\n",
    "def explore_video(b):\n",
    "    with video_output:\n",
    "        # Create Video File\n",
    "        video_output.clear_output()\n",
    "#         html_video_code = '<video width=\"80%\" height=\"80%\" controls><source src=\"./data/rgbVideos/{fileName}\" type=\"video/mp4\"></video>'.format(fileName = ddl_data_selected.value)\n",
    "        html_video_code = '<video width=\"80%\" height=\"80%\" controls><source src=\"./videosCaptionOutput/P02T02C06.mp4\" type=\"video/mp4\"></video>'\n",
    "\n",
    "        video_output.append_display_data(HTML(html_video_code))\n",
    "\n",
    "btn_video.on_click(explore_video)\n",
    "\n",
    "# CLear output\n",
    "def clear_video(b):\n",
    "    with video_output:\n",
    "        video_output.clear_output()\n",
    "        \n",
    "btn_clear.on_click(clear_video)\n",
    "\n",
    "# Display\n",
    "data_box = widgets.VBox([widgets.HBox([label_data_files, ddl_data_selected])])\n",
    "data_btn_box = widgets.VBox([widgets.HBox([btn_clear, btn_video]),video_output])\n",
    "\n",
    "display(data_box)\n",
    "display(data_btn_box)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3163bb07",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction\n",
    "This section performs feature extractions from videos into numpy format, so that it can be used to perform inferencing, training and testing.\n",
    "\n",
    "### Parameters:\n",
    "- Folder & File\n",
    "    - Locate the directory where your videos are stored for feature extraction\n",
    "    - Select one one or more videos\n",
    "- Stream Type\n",
    "    - Select between `null, rgb, flow` stream types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c89a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widgets\n",
    "\n",
    "sub_folders = [name for name in os.listdir('./data') if os.path.isdir(os.path.join('./data', name))]\n",
    "sub_folders.remove('.ipynb_checkpoints')\n",
    "sub_folders = sorted(sub_folders,reverse=True)\n",
    "\n",
    "list_of_videos = []\n",
    "\n",
    "label_video_folder = widgets.Label(\"Select Folder:\", layout = label_layout)\n",
    "ddl_video_folder = widgets.Dropdown(\n",
    "    options=sub_folders,\n",
    "    layout = btn_layout)\n",
    "\n",
    "label_stream = widgets.Label(\"Select Stream:\", layout = label_layout)\n",
    "ddl_stream = widgets.Select(\n",
    "    options=['null', 'rgb', 'flow'],\n",
    "    value='null',\n",
    "    layout = ddl_layout)\n",
    "\n",
    "btn_confirm_folder = widgets.Button(description=\"Confirm Folder\", layout = btn_layout, button_style='info')\n",
    "\n",
    "def selectvideos(b):\n",
    "    for (dirpath, dirnames, filenames) in walk('./data/rgbVideos/'):\n",
    "        list_of_videos.extend(filenames)\n",
    "        break\n",
    "    label_feature_files= widgets.Label(\"Select Video(s):\", layout = label_layout)\n",
    "    ddl_feature_files = widgets.SelectMultiple(\n",
    "        options=list_of_videos,\n",
    "        layout = ddl_layout)\n",
    "    test_box = widgets.VBox([widgets.HBox([label_feature_files, ddl_feature_files]),\n",
    "                     widgets.HBox([label_stream, ddl_stream]), btn_extract])\n",
    "    display(test_box)\n",
    "    \n",
    "btn_confirm_folder.on_click(selectvideos)\n",
    "\n",
    "btn_extract = widgets.Button(description=\"Extract Features\", layout = btn_layout, button_style='info')\n",
    "\n",
    "# Display\n",
    "feature_box = widgets.VBox([widgets.HBox([label_video_folder, ddl_video_folder]),\n",
    "                            btn_confirm_folder])\n",
    "feature_box\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e99aa",
   "metadata": {},
   "source": [
    "## 5. Inference\n",
    "This is the inference section where users can test and evaluate how accurate their model is in the actual video itself, comparing the ground truth and generated annotations.\n",
    "\n",
    "### Parameters:\n",
    "- Model \n",
    "  - Select from one of the pre-trained ML models\n",
    "- Input Video \n",
    "  - Select an input video from the `/data/rgbVideos` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "100eceaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/rgbVideos` directory contains 536 file(s).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99e1af03d244c13b01899ebd5d3a07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Select Model:', layout=Layout(height='auto', width='200px')), Dropd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3550e66be4b64845892ecf0674acac20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Run Inferencing', layout=Layout(height='40px', width='45%'), style=Bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4393533460d94970bc6323158e76f9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logic\n",
    "model_dir = './TSU/models/'\n",
    "# listdir() returns a list containing the names of the entries in the directory given by path.\n",
    "modelList = os.listdir(\"./TSU/models\")\n",
    "train_modelList = os.listdir(\"./TSU/PDAN\")\n",
    "modelList += train_modelList\n",
    "\n",
    "## retrieve all TSU videos to dropdown list\n",
    "folder_files = os.listdir('data/rgbVideos') \n",
    "print(\"data/rgbVideos` directory contains {len_folder} file(s).\".format(len_folder=len(folder_files)))\n",
    "fileList=[]\n",
    "for file in folder_files:\n",
    "    fileList.append(file)\n",
    "\n",
    "# Widgets\n",
    "label_inference_model = widgets.Label(\"Select Model:\", layout = label_layout)\n",
    "ddl_inference_model = widgets.Dropdown(\n",
    "    options = modelList,\n",
    "    value = modelList[0],\n",
    "    layout = btn_layout)\n",
    "\n",
    "label_inference_video = widgets.Label(\"Select Input Video:\", layout = label_layout)\n",
    "selected_input_video = widgets.Dropdown(\n",
    "    options = fileList,\n",
    "    value= fileList[0],\n",
    "    layout = btn_layout)\n",
    "\n",
    "btn_inference = widgets.Button(description=\"Run Inferencing\", layout = btn_layout, button_style='info')\n",
    "\n",
    "# Display\n",
    "model_box = widgets.HBox([label_inference_model, ddl_inference_model])\n",
    "inference_box = widgets.VBox([model_box, widgets.HBox([label_inference_video, selected_input_video])])\n",
    "inference_output = widgets.Output()\n",
    "display(inference_box)\n",
    "display(btn_inference)\n",
    "display(inference_output)\n",
    "\n",
    "###### Generate and Save captions Function ###################\n",
    "class Captioning:\n",
    "    def __init__(self, annotation_file_path, truth_file_path, video_file):\n",
    "        self.sf = pandas.read_csv(annotation_file_path, header=0, names=['action','start','end','accuracy'], usecols=['action','start','end','accuracy'])[['action','start','end','accuracy']]\n",
    "        self.df = pandas.read_csv(truth_file_path)\n",
    "        self.video_path = video_file\n",
    "        self.time = 0\n",
    "        self.nextTime = 0\n",
    "        self.nextActionTime = 0\n",
    "        self.eventCounter = 0\n",
    "        self.actionCounter = 0\n",
    "        self.prediction = 0.0\n",
    "        self.ground_truth = \"\"\n",
    "        self.caption = \"\"\n",
    "        self.output_path = \"./videosCaptionOutput/\"\n",
    "\n",
    "    def getGroundTruth(self):\n",
    "        if self.time == 0:\n",
    "            self.nextTime = self.df['start_frame'].iloc[1]\n",
    "\n",
    "        if self.time >= self.nextTime:\n",
    "            try:\n",
    "                self.ground_truth = self.df['event'].iloc[self.eventCounter]\n",
    "                self.ground_truth =  re.sub('[_,.]', ' ', self.ground_truth)\n",
    "                self.nextTime = self.df['start_frame'].iloc[self.eventCounter+1]\n",
    "                self.eventCounter += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "    def getCaption(self):\n",
    "        if self.actionCounter == 0:\n",
    "            self.actionCounter, = self.sf.index[self.sf['end'] == 'end']\n",
    "            \n",
    "        if self.time >= self.nextActionTime:\n",
    "            self.actionCounter += 1\n",
    "            try: \n",
    "                self.nextActionTime = float(self.sf['end'].iloc[self.actionCounter])\n",
    "                self.caption = self.sf['action'].iloc[self.actionCounter]\n",
    "                self.caption =  re.sub('[_,.]', ' ', self.caption)\n",
    "                self.prediction = float(self.sf['accuracy'].iloc[self.actionCounter])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "    def saveVideo(self):\n",
    "        if not os.path.exists('./videosCaptionOutput/'):\n",
    "            os.makedirs('./videosCaptionOutput/')\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        # and our buffer to write frames\n",
    "#         fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'H264')\n",
    "        out = cv2.VideoWriter(self.output_path+str(self.video_path[len(self.video_path)-13:len(self.video_path)-4])+'.mp4', fourcc, 25, (int(cap.get(3)),int(cap.get(4))))\n",
    "        if (cap.isOpened() == False):\n",
    "            print(\"Error opening video stream or file\")\n",
    "        counter = 0\n",
    "        length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        progress_bar_instance = progress_bar(length)\n",
    "        progress_bar_instance.display_bar()\n",
    "        while (cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f'Video annotation is process complete.')\n",
    "                break\n",
    "\n",
    "            height, width, channels = frame.shape\n",
    "\n",
    "            self.time = int(cap.get(cv2.CAP_PROP_POS_MSEC)/40)\n",
    "            self.getGroundTruth()\n",
    "            self.getCaption()\n",
    "    \n",
    "#             print(self.time, self.caption)\n",
    "            cv2.rectangle(frame, (int(width * 0.05), int(height * 0.8)), (int(width * 0.95), int(height*0.95)), (159,159,159), -1)\n",
    "            cv2.putText(frame, \"Ground truth\", (int(width*0.1),int(height*0.85)), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,0), 2)\n",
    "            cv2.putText(frame, self.ground_truth, (int(width*0.3),int(height*0.85)), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,0), 2)\n",
    "            cv2.putText(frame, \"Prediction\", (int(width*0.1),int(height*0.9)), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,0), 2)\n",
    "            cv2.putText(frame, self.caption, (int(width*0.3),int(height*0.9)), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,0), 2)\n",
    "            cv2.putText(frame, \"Accuracy\", (int(width*0.65),int(height*0.9)), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,0), 2)\n",
    "            cv2.putText(frame, str(self.prediction), (int(width*0.8),int(height*0.9)), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,0), 2)\n",
    "\n",
    "            #write our frame\n",
    "            out.write(frame)\n",
    "            cv2.imshow('frame',frame)\n",
    "\n",
    "            key = cv2.waitKey(1)\n",
    "            # define the key to\n",
    "            # close the window\n",
    "            if key == 'q' or key == 27:\n",
    "                break\n",
    "            progress_bar_instance.update_bar()\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()       \n",
    "    \n",
    "# Usage Captioning(annotation_file_path, truth_file_path, video_file) \n",
    "# annotation_file_path (e.g. \"./data/generatedAnnotations/PDAN_TSU_RGB_P02T01C06.csv\" )\n",
    "# truth_file_path (e.g. \"./data/annotations/P02/P02T01C06.csv\" )\n",
    "# video_file (e.g. \"./data/rgbVideos/P02T01C06.mp4\")\n",
    "\n",
    "###### Generate CSV After running Inferencing ###########################\n",
    "def run_inferencing(b):\n",
    "    with inference_output:\n",
    "        clear_output()\n",
    "        video_data = selected_input_video.value.replace(\".mp4\",\"\")\n",
    "        inference_json(video_data, \"TSU\")\n",
    "        if (ddl_inference_model.value == \"PDAN_TSU_RGB\"):\n",
    "            sub_dir = \"./TSU/models/\"\n",
    "        else:\n",
    "            sub_dir = \"./TSU/PDAN/\"\n",
    "        inf_dir = sub_dir + ddl_inference_model.value\n",
    "        inference_dataset = \"inference_smarthome_CS_51.json\"\n",
    "        dataset_type = \"TSU\"\n",
    "        %run ./TSU/inferencing.py -load_model $inf_dir -video_name $selected_input_video.value -dataset $inference_dataset -dataset_type $dataset_type\n",
    "        sub_folder = selected_input_video.value[:3]\n",
    "        gt_annotation_directory = \"./data/annotations/{folder}/\".format(folder=sub_folder)\n",
    "        generated_annotation_directory = \"./data/generatedAnnotations/\"\n",
    "        annotation_file = selected_input_video.value.replace(\".mp4\",\".csv\")\n",
    "        gen_annotation_file = \"{loaded_model}_{vid_name}\".format(loaded_model=ddl_inference_model.value, vid_name=annotation_file)\n",
    "        video_directory = \"./data/rgbVideos/{vid_name}\".format(vid_name=selected_input_video.value)\n",
    "        print(\"video is processing now..\")\n",
    "        test1 = Captioning(generated_annotation_directory+gen_annotation_file, gt_annotation_directory+annotation_file, video_directory)\n",
    "        test1.saveVideo()\n",
    "        html_video_code = '<video width=\"80%\" height=\"80%\" controls><source src=\"./videosCaptionOutput/{video}\" type=\"video/mp4\"></video>'.format(video=selected_input_video.value)\n",
    "\n",
    "        inference_output.append_display_data(HTML(html_video_code))\n",
    "\n",
    "btn_inference.on_click(run_inferencing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e059f3d",
   "metadata": {},
   "source": [
    "## 5. Training\n",
    "//// INSERT DESCRIPTION HERE //////\n",
    "\n",
    "### Select dataset:\n",
    "- Select a dataset from the `data` folder for input for the training & testing functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c88918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fc0ce11",
   "metadata": {},
   "source": [
    "### Initialise Training\n",
    "  - Video Type\n",
    "  - Model Name\n",
    "  - Batch_Size\n",
    "  - Epoch\n",
    "  - Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2bec4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fca6e07b",
   "metadata": {},
   "source": [
    "## 6. Testing\n",
    "//// INSERT DESCRIPTION HERE //////\n",
    "\n",
    "Your dataset has already been selected in section 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a1e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---print number of videos in testing here\")\n",
    "\n",
    "# Widget\n",
    "btn_testing = widgets.Button(description=\"Run Testing\", layout = btn_layout, button_style='info')\n",
    "\n",
    "# Display\n",
    "display(model_box)\n",
    "display(btn_testing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
